To update the `glide.iamidsidentities` table in your MySQL database with the records from the DataFrame while only updating the columns present in your DataFrame (and leaving others unchanged), you can modify your code as follows:

### Key Changes:
- Instead of using an `INSERT` statement, you will use an `UPDATE` statement.
- The `UPDATE` will only affect the rows identified by the primary key (`resourceid`).
- You will only update the columns that are present in the DataFrame, leaving other columns untouched.
- We will ensure that only the records where there are changes (based on the DataFrame) will be updated.

Here's the updated code:

```python
import pandas as pd
import pymysql

# Example DataFrame (for illustration, this DataFrame has 109 columns)
# Let's say this is your DataFrame with a column 'ManagerLevel' which should map to 'level'
df = pd.DataFrame({
    f'column_{i}': range(1, 6) for i in range(1, 109)
})

# Add the column that needs to be renamed for the MySQL table
df['ManagerLevel'] = [1, 2, 3, 4, 5]  # Sample data for ManagerLevel

# Connect to MySQL using pymysql
conn = pymysql.connect(
    host='localhost',
    user='username',
    password='password',
    database='yourdb'
)

cursor = conn.cursor()

# Step 1: Get the column names from your MySQL table (ensure the correct order)
cursor.execute("DESCRIBE glide.iamidsidentities;")
table_columns = [column[0] for column in cursor.fetchall()]

# Step 2: Create a column mapping to handle the name mismatch (ManagerLevel â†’ level)
column_mapping = {
    'ManagerLevel': 'level',  # Map 'ManagerLevel' in DataFrame to 'level' in MySQL
}

# Adjust the DataFrame columns according to the mapping (rename 'ManagerLevel' to 'level')
df.rename(columns=column_mapping, inplace=True)

# Step 3: Check if the DataFrame columns exist in the MySQL table
df_columns = df.columns.tolist()
valid_columns = [col for col in df_columns if col in table_columns]

# Step 4: Create the SQL UPDATE statement
update_query_template = """
    UPDATE glide.iamidsidentities 
    SET {set_clause} 
    WHERE resourceid = %s;
"""

# Step 5: Prepare data for updating in batches (so it doesn't overwhelm the MySQL server)
batch_size = 1000  # Example batch size (adjust as needed)

# Generate the SET clause for the UPDATE statement dynamically based on valid columns
for start in range(0, len(df), batch_size):
    end = start + batch_size
    batch = df.iloc[start:end]

    # Create the set clause dynamically based on DataFrame columns
    set_clause = ', '.join([f"{col} = %s" for col in valid_columns])

    # Prepare the data for the query, including 'resourceid' and the values for the set clause
    data_to_update = []
    for _, row in batch.iterrows():
        row_data = [row[col] for col in valid_columns]
        resource_id = row['resourceid']  # Assuming 'resourceid' is in the DataFrame
        data_to_update.append(tuple(row_data + [resource_id]))

    # Execute the update query for the current batch
    for data in data_to_update:
        update_query = update_query_template.format(set_clause=set_clause)
        cursor.execute(update_query, data)

    conn.commit()  # Commit the batch update operation

# Close the cursor and connection
cursor.close()
conn.close()
```

### Explanation of Changes:
1. **Dynamic Update Query**: The `SET` part of the SQL `UPDATE` statement is created dynamically based on the columns present in your DataFrame that also exist in the MySQL table. This way, only the relevant columns are updated.
   
2. **Using `resourceid`**: The `WHERE` clause in the `UPDATE` statement uses `resourceid`, which is assumed to be the primary key. This ensures that only the records corresponding to the `resourceid` will be updated.

3. **Batch Processing**: The data is updated in batches, similar to your original `INSERT` strategy, to prevent overwhelming the database server with too many requests at once.

4. **Preserving Unchanged Columns**: Columns that are not present in the DataFrame or are not included in the `valid_columns` list will remain unchanged.

### Things to Note:
- Ensure that `resourceid` is included in the DataFrame (`df`), or you can modify the logic to fetch it from the table if it's not present in the DataFrame.
- Depending on the size of your DataFrame and database, you may need to tweak the `batch_size` to optimize performance.

Let me know if you need further adjustments or clarifications!