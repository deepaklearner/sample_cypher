Here is the **full, cleaned-up version** of your `IAMDataIngestion` class with:

* ✅ Retry logic (without 3rd-party libraries)
* ✅ `reconnect()` and `connect_to_edw()` methods
* ✅ Applied to `fetch_Batchdata_from_entitlement_master` (you can easily extend to others)
* ✅ Logging and exponential backoff

---

### ✅ Updated `data_ingestion.py`:

```python
import pymysql
import logging
import yaml
import pandas as pd
import time


class IAMDataIngestion:
    """
    This class contains all data ingestion scenarios from upstream sources.
    """

    def __init__(self, database_configs, sql_yaml_file, delta_load_file, load_type, source):
        self.sql_yaml_file = sql_yaml_file
        self.delta_load_file = delta_load_file
        self.source = source
        self.load_type = load_type
        self.database_configs = database_configs

        try:
            self.connect_to_edw()
            logging.info("EDW connection opened successfully!")
            self.sql_qrys = self.load_local_sql_query_yaml()
        except Exception as e:
            logging.error(f"Exception occurred at get source database connection: {str(e)}")

    def connect_to_edw(self):
        """
        Create a new EDW connection using config
        """
        ssl_options = {
            'ssl': {
                'ssl_version': self.database_configs['EDW']["TLSVersions"]
            }
        }

        self.edw_connection = pymysql.connect(
            user=self.database_configs['EDW']['Username'],
            password=self.database_configs['EDW']['Password'],
            host=self.database_configs['EDW']['Hostname'],
            database=self.database_configs['EDW']['Database'],
            **ssl_options
        )

    def reconnect(self):
        """
        Attempt to reconnect to the database
        """
        try:
            logging.warning("Attempting to reconnect to EDW...")
            self.connect_to_edw()
            logging.info("Reconnected to EDW successfully.")
        except Exception as e:
            logging.error(f"Failed to reconnect to EDW: {str(e)}")
            raise

    def load_local_sql_query_yaml(self):
        """
        Read SQL query YAML file.
        """
        try:
            with open(self.sql_yaml_file, 'r') as stream:
                return yaml.safe_load(stream)
        except yaml.YAMLError as e:
            logging.error(f"Error reading SQL YAML file: {str(e)}")
            return {}

    def load_delta_times_yaml(self):
        """
        Read delta time configuration.
        """
        try:
            with open(self.delta_load_file, 'r') as stream:
                return yaml.safe_load(stream)
        except yaml.YAMLError as e:
            logging.error(f"Error reading delta YAML file: {str(e)}")
            return {}

    def close_connections(self):
        """
        Close active DB connections.
        """
        try:
            if self.source.lower() == 'glide' and hasattr(self, 'glide_connection'):
                self.glide_connection.close()
                logging.info("GLIDE connection closed successfully!")
            elif hasattr(self, 'edw_connection') and self.edw_connection.open:
                self.edw_connection.close()
                logging.info("EDW connection closed successfully!")
        except Exception as e:
            logging.error(f"Error closing {self.source} connection: {str(e)}")

    def fetch_Batchdata_from_entitlement_master(self, feature_name, sql_query_param, chunksize, offset, max_retries=3):
        """
        Fetch batched data from Entitlement Master with retry mechanism.
        """
        attempt = 0
        while attempt < max_retries:
            try:
                if not self.edw_connection or not self.edw_connection.open:
                    self.reconnect()

                query = self.sql_qrys['edw_query'][sql_query_param]
                query = f"{query} LIMIT {chunksize} OFFSET {offset}"
                return pd.read_sql(query, con=self.edw_connection)

            except (pymysql.err.OperationalError, pymysql.err.InterfaceError) as e:
                attempt += 1
                logging.warning(f"Retry {attempt}/{max_retries} for offset {offset}: {str(e)}")
                time.sleep(2 ** attempt)  # exponential backoff
                self.reconnect()
            except Exception as e:
                logging.error(f"Unrecoverable error for offset {offset}: {str(e)}")
                break

        logging.error(f"All {max_retries} attempts failed for batch at offset {offset}")
        return pd.DataFrame()  # Return empty DataFrame to avoid crashing

    def fetch_data_from_edw(self, feature_name, sql_query_param):
        """
        Fetch full data for a feature from EDW.
        """
        try:
            if self.load_type == "full":
                query = self.sql_qrys['edw_query'][sql_query_param]
                return pd.read_sql(query, con=self.edw_connection)
        except Exception as e:
            logging.error(f"Exception in fetch_data_from_edw({feature_name}): {str(e)}")

    def fetch_data_from_eservice_data(self, feature_name, sql_query_param, placeholders, keys):
        """
        Fetch data from E-Service based on placeholders and keys.
        """
        try:
            if not self.edw_connection or not self.edw_connection.open:
                self.reconnect()

            query = self.sql_qrys['edw_query'][sql_query_param].format(placeholders=placeholders)
            return pd.read_sql(query, con=self.edw_connection, params=keys)
        except Exception as e:
            logging.error(f"Exception in fetch_data_from_eservice_data({feature_name}): {str(e)}")
```

---

### 🔁 You Can Now:

* Use `fetch_Batchdata_from_entitlement_master(..., max_retries=3)` in your main script.
* Apply similar logic to `fetch_data_from_edw` or others if needed.

Would you like me to show how to update `main.py` to pass the `max_retries` parameter as well?
