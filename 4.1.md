Certainly! Here's a simpler way to add a retry mechanism to your MySQL connection without using external libraries like `tenacity`. We'll use basic Python logic to retry on connection or query failures.

### Simple Retry Mechanism Without External Libraries

```python
import mysql.connector
import time

# Simple retry function
def retry_connection(func, max_retries=5, delay=2):
    attempt = 0
    while attempt < max_retries:
        try:
            return func()
        except (mysql.connector.errors.OperationalError, mysql.connector.errors.InterfaceError) as e:
            attempt += 1
            print(f"Connection failed, retrying {attempt}/{max_retries}...")
            time.sleep(delay)
            delay *= 2  # Exponential backoff
    raise Exception("Max retries reached, could not connect to the database.")

def connect_to_db():
    return mysql.connector.connect(
        host='your_host',
        user='your_user',
        password='your_password',
        database='your_database',
        autocommit=True
    )

def read_in_batches(batch_size=25000):
    offset = 0
    while True:
        try:
            conn = retry_connection(connect_to_db)
            cursor = conn.cursor(dictionary=True)
            query = f"SELECT * FROM your_table LIMIT {batch_size} OFFSET {offset}"
            cursor.execute(query)
            rows = cursor.fetchall()

            if not rows:
                break

            # Process the batch of rows
            print(f"Processing batch starting at offset {offset} with {len(rows)} rows")
            offset += batch_size

            cursor.close()
            conn.close()

        except Exception as e:
            print(f"Error occurred while reading batch at offset {offset}: {e}")
            break  # Optionally break out if error is not recoverable.

read_in_batches()
```

### Explanation:

* **`retry_connection`**: This function tries to call the `connect_to_db` function multiple times (up to `max_retries`), with an increasing delay between attempts (exponential backoff).
* **Error Handling**: If a connection error occurs, it retries up to `max_retries` times.
* **Exponential Backoff**: Delay starts at `2 seconds` and doubles each time (2, 4, 8 seconds) to reduce load.
* **Batch Processing**: The script fetches rows in batches of 25,000 (or any number you set) and processes them. It continues until no more rows are found.

---

This approach is simpler, as it only relies on Python's built-in `time.sleep` for the delay between retries, and handles MySQL connection errors directly.
