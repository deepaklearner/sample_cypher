import logging

def update_data_to_identities(self, df, chunk_size=10000):
    """
    Update data in the Glide identities table.
    """
    def get_table_columns(cursor):
        """
        Fetch the column names from the 'glide.glideidentities' table.
        """
        cursor.execute("DESCRIBE glide.glideidentities;")
        return [column[0] for column in cursor.fetchall()]


    def prepare_data_for_update(df, table_columns):
        """
        Prepares the DataFrame by renaming columns and selecting only required ones.
        """
        df_new = df.rename(columns={"EmployeeID": "resourceid"})
        req_columns = [col for col in df_new.columns if col in table_columns]
        set_clause = ", ".join([f"{col} = %s" for col in req_columns])
        return df_new, req_columns, set_clause


    def get_glide_resource_ids(cursor, resourceid_ids):
        """
        Get existing resourceid values from the database.
        """
        format_strings = ", ".join(["%s"] * len(resourceid_ids))
        query = f"SELECT resourceid FROM glide.glideidentities WHERE resourceid IN ({format_strings})"
        cursor.execute(query, tuple(resourceid_ids))
        return set(row[0] for row in cursor.fetchall())


    def log_missing_resource_ids(missing_resource_ids):
        """
        Logs the missing resource IDs in batches.
        """
        if missing_resource_ids:
            logging.info(f"Missing resourceid values in glide.glideidentities: {missing_resource_ids}")


    def update_data_batch(cursor, update_query, data_to_update):
        """
        Executes the update query for a batch of data.
        """
        try:
            cursor.executemany(update_query, data_to_update)
        except Exception as e:
            logging.error(f"Error processing batch: {str(e)}")
            cursor.connection.rollback()
            raise

    try:
        cursor = self.glide_connection.cursor()

        # Fetch table columns
        table_columns = 1(cursor)

        # Prepare DataFrame for update
        df_new, req_columns, set_clause = prepare_data_for_update(df, table_columns)

        update_query_template = f"UPDATE glide.glideidentities SET {set_clause} WHERE resourceid = %s"

        # Fetch all existing resource IDs in one go
        graphdb_resource_ids = df_new['resourceid'].unique().tolist()
        glide_resource_ids = get_glide_resource_ids(cursor, graphdb_resource_ids)

        # Log all missing resource IDs at once
        missing_resource_ids = [resource_id for resource_id in graphdb_resource_ids if resource_id not in glide_resource_ids]
        logging.info(f"Count of missing resource_ids: {len(missing_resource_ids)}")
        log_missing_resource_ids(missing_resource_ids)

        # Filter out rows with missing resource IDs
        df_new = df_new[df_new['resourceid'].isin(glide_resource_ids)]
        logging.info(f"Count of df_new: {df_new.shape[0]}")

        # Precompute column indices
        req_columns_idx = [df_new.columns.get_loc(col) for col in req_columns]
        resourceid_idx = df_new.columns.get_loc('resourceid')

        # Insert in chunks using executemany
        for start in range(0, len(df_new), chunk_size):
            end = start + chunk_size
            batch = df_new.iloc[start:end]

            # Prepare data for update
            batch_values = batch.values
            data_to_update = [
                tuple([row[idx] for idx in req_columns_idx] + [row[resourceid_idx]])
                for row in batch_values
            ]

            # Execute batch update
            update_data_batch(cursor, update_query_template, data_to_update)

        self.glide_connection.commit()
        cursor.close()
        logging.info(f"Data updated in Glide identities table successfully for {len(df_new)} records.")

    except Exception as e:
        logging.error(f"Error fetching data: {str(e)} - Debug <Class: IAM DataExport | Method: update_data_to_identities()>")
        if self.glide_connection:
            self.glide_connection.rollback()
        raise
