import csv
import yaml
import os
from datetime import datetime

# Read configuration from YAML
with open("config.yaml", "r") as config_file:
    config = yaml.safe_load(config_file)

# Get output file location from the config
output_file = config.get("report", {}).get("output_file_location")

# Validate configuration
if not output_file:
    raise ValueError("Output file location is not configured in 'config.yaml'.")

# Extract directory, base name, and extension
output_dir = os.path.dirname(output_file)
base_name, ext = os.path.splitext(os.path.basename(output_file))

# Add datetime stamp to the file name
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_file_with_timestamp = os.path.join(output_dir, f"{base_name}_{timestamp}{ext}")

# Ensure the directory exists
if output_dir and not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Define batch size
BATCH_SIZE = 12

# Initialize batch offset
offset = 0
flag = False

# Open the output file for appending data
with open(output_file_with_timestamp, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    header_written = False

    with graph_cnx as cnx:
        while True:
            try:
                # Cypher query to fetch a batch of data
                query = f"""
                MATCH (u:User) 
                WHERE u.managerid IS NOT NULL 
                OPTIONAL MATCH (u)-[:REPORTS_TO*1..4]->(m:User)
                RETURN u.employeeNumber AS employeeNumber, u.managerid AS managerid
                SKIP {offset} LIMIT {BATCH_SIZE}
                """

                # Execute the query
                result = graph_cnx.driver.execute_query(query)
                records = result.records()

                # Exit loop if no more records are found
                if not records:
                    break

                # Write header only once
                if not header_written:
                    writer.writerow(result.keys())  # Writes column headers
                    header_written = True

                # Write data rows
                for record in records:
                    writer.writerow(record)

                # Increment offset for the next batch
                offset += BATCH_SIZE

            except exceptions.Neo4jError as e:
                flag = True
                print(f"Error executing Cypher query batch at offset {offset}: {e}")
                break

if flag:
    print("Supervisor hierarchy report creation unsuccessful, please debug logs.")
else:
    print(f"Supervisor hierarchy report created successfully at {output_file_with_timestamp}.")
