Here is the full code with the missing `resourceid` values logging added:

```python
import pandas as pd
import pymysql
import numpy as np

# Connect to MySQL using pymysql
conn = pymysql.connect(
    host='localhost',
    user='username',
    password='password',
    database='yourdb'
)

cursor = conn.cursor()

# Step 1: Get the column names from your MySQL table (ensure the correct order)
cursor.execute("DESCRIBE glide.iamidsidentities;")
table_columns = [column[0] for column in cursor.fetchall()]

# Step 2: Create a column mapping to handle the name mismatch (ManagerLevel â†’ level)
column_mapping = {
    'ManagerLevel': 'level',  # Map 'ManagerLevel' in DataFrame to 'level' in MySQL
}

# Assuming df is already loaded, you would still need to rename columns
df.rename(columns=column_mapping, inplace=True)

# Step 3: Check if the DataFrame columns exist in the MySQL table
df_columns = df.columns.tolist()
valid_columns = [col for col in df_columns if col in table_columns]

# Step 4: Create the SQL UPDATE statement template
update_query_template = """
    UPDATE glide.iamidsidentities 
    SET {set_clause} 
    WHERE resourceid = %s;
"""

# Prepare the set clause based on valid columns in the DataFrame
set_clause = ', '.join([f"{col} = %s" for col in valid_columns])

# Step 5: Retrieve the resourceid values from the MySQL table 'iamidsidentities'
cursor.execute("SELECT resourceid FROM glide.iamidsidentities;")
existing_resource_ids = set(row[0] for row in cursor.fetchall())

# Step 6: Find resourceid values in df that are not in iamidsidentities
missing_resource_ids = df[~df['resourceid'].isin(existing_resource_ids)]['resourceid'].tolist()

# Log the missing resourceid values
if missing_resource_ids:
    print(f"Missing resourceid values from iamidsidentities: {missing_resource_ids}")
else:
    print("No missing resourceid values found.")

# Step 7: Update records in batches
batch_size = 10000  # Adjust batch size for large data, based on server capabilities
batch_counter = 0

# Prepare Numpy arrays for faster operations
valid_columns_idx = [df.columns.get_loc(col) for col in valid_columns]  # Get column indices for valid columns
resourceid_idx = df.columns.get_loc('resourceid')  # Assuming 'resourceid' is in the DataFrame

# Process the data in chunks from the DataFrame (streaming approach)
for start in range(0, len(df), batch_size):
    end = start + batch_size
    batch = df.iloc[start:end]

    # Prepare the data to update, adding resourceid as the last element in each tuple
    batch_values = batch.values  # Convert the DataFrame chunk into a Numpy array

    # Select the relevant data for valid columns (ignoring the columns that are not valid)
    data_to_update = []
    for row in batch_values:
        row_data = [row[idx] for idx in valid_columns_idx]
        resource_id = row[resourceid_idx]  # Get the resourceid for the WHERE clause
        data_to_update.append(tuple(row_data + [resource_id]))

    # Execute the update query for the current batch
    try:
        for data in data_to_update:
            update_query = update_query_template.format(set_clause=set_clause)
            cursor.execute(update_query, data)
        conn.commit()  # Commit after processing the batch
        batch_counter += 1
        print(f"Processed batch {batch_counter}")
    except Exception as e:
        print(f"Error processing batch {batch_counter}: {e}")
        conn.rollback()  # Rollback if something goes wrong with the batch

# Close the cursor and connection after processing all batches
cursor.close()
conn.close()

print(f"Finished processing all {len(df)} records.")
```

### Key Additions:
- **Step 5**: Retrieves all `resourceid` values from the `iamidsidentities` table into `existing_resource_ids`.
- **Step 6**: Finds the `resourceid` values in `df` that are not in `existing_resource_ids`.
- **Logging**: If there are any missing `resourceid` values, it will log those to the console. If no missing `resourceid` values are found, it logs that as well.

Now the script will check for `resourceid` values in `df` that aren't in the `iamidsidentities` table and log those values before starting the batch updates.