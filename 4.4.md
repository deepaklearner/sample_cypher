Perfect â€” letâ€™s fully refactor `fetch_data_from_eservice_data()` using the **common retry wrapper** approach inside your `IAMDataIngestion` class.

---

## âœ… Step-by-step Final Version:

### âœ… 1. Add a private helper method to run any SQL query:

```python
def _execute_query(self, query, params=None):
    return pd.read_sql(query, con=self.edw_connection, params=params)
```

---

### âœ… 2. Add the retry wrapper:

```python
def retry_db_operation(self, operation, *args, max_retries=3, **kwargs):
    attempt = 0
    while attempt < max_retries:
        try:
            if not self.edw_connection or not self.is_connection_alive():
                self.reconnect()

            return operation(*args, **kwargs)

        except (pymysql.err.OperationalError, pymysql.err.InterfaceError) as e:
            attempt += 1
            logging.warning(f"Retry {attempt}/{max_retries} for {operation.__name__}: {str(e)}")
            time.sleep(2 ** attempt)
            self.reconnect()

        except Exception as e:
            logging.error(f"Unrecoverable error in {operation.__name__}: {str(e)}")
            break

    logging.error(f"All {max_retries} attempts failed for {operation.__name__}")
    return pd.DataFrame()
```

---

### âœ… 3. Add a helper to check connection health:

```python
def is_connection_alive(self):
    try:
        self.edw_connection.ping(reconnect=False)
        return True
    except:
        return False
```

---

### âœ… 4. Refactor `fetch_data_from_eservice_data()`:

Replace your existing method with this:

```python
def fetch_data_from_eservice_data(self, feature_name, sql_query_param, placeholders, keys, max_retries=3):
    """
    Fetch data from E-Service with retry logic.
    """
    try:
        query = self.sql_qrys['edw_query'][sql_query_param].format(placeholders=placeholders)
        return self.retry_db_operation(self._execute_query, query, params=keys, max_retries=max_retries)
    except Exception as e:
        logging.error(f"Error building query in fetch_data_from_eservice_data: {str(e)}")
        return pd.DataFrame()
```

---

## âœ… Example Use (in main.py or executor):

```python
eservice_df = iam_ingestion.fetch_data_from_eservice_data(
    feature_name,
    sql_eservice,
    placeholders,
    keys,
    max_retries=3
)
```

---

## ðŸ”š Summary

This version:

* Uses a **common retry mechanism**
* Applies clean separation between **query logic** and **retry logic**
* Can be reused for any database method in the class

Would you like me to refactor `fetch_Batchdata_from_entitlement_master()` in the same style as well?


Great â€” hereâ€™s how to fully refactor `fetch_Batchdata_from_entitlement_master()` using the same **retry wrapper** pattern for consistency and robustness.

---

## âœ… Final Refactored Version

### ðŸ” 1. Keep the shared helpers you already added:

If you havenâ€™t already, ensure your class includes:

```python
def _execute_query(self, query, params=None):
    return pd.read_sql(query, con=self.edw_connection, params=params)

def retry_db_operation(self, operation, *args, max_retries=3, **kwargs):
    attempt = 0
    while attempt < max_retries:
        try:
            if not self.edw_connection or not self.is_connection_alive():
                self.reconnect()

            return operation(*args, **kwargs)

        except (pymysql.err.OperationalError, pymysql.err.InterfaceError) as e:
            attempt += 1
            logging.warning(f"Retry {attempt}/{max_retries} for {operation.__name__}: {str(e)}")
            time.sleep(2 ** attempt)
            self.reconnect()

        except Exception as e:
            logging.error(f"Unrecoverable error in {operation.__name__}: {str(e)}")
            break

    logging.error(f"All {max_retries} attempts failed for {operation.__name__}")
    return pd.DataFrame()

def is_connection_alive(self):
    try:
        self.edw_connection.ping(reconnect=False)
        return True
    except:
        return False
```

---

### ðŸ” 2. Refactor `fetch_Batchdata_from_entitlement_master()`:

```python
def fetch_Batchdata_from_entitlement_master(self, feature_name, sql_query_param, chunksize, offset, max_retries=3):
    """
    Fetch batched data from Entitlement Master using retry logic.
    """
    try:
        base_query = self.sql_qrys['edw_query'][sql_query_param]
        full_query = f"{base_query} LIMIT {chunksize} OFFSET {offset}"
        return self.retry_db_operation(self._execute_query, full_query, max_retries=max_retries)
    except Exception as e:
        logging.error(f"Error building query in fetch_Batchdata_from_entitlement_master: {str(e)}")
        return pd.DataFrame()
```

---

## âœ… How to Call It

In your main processing method (e.g., `create_graph_for_entitlements`), just pass `max_retries` as needed:

```python
ent_raw = iam_ingestion.fetch_Batchdata_from_entitlement_master(
    feature_name,
    sql_entitlements,
    chunksize,
    offset,
    max_retries=3  # Or pull from config
)
```

---

## ðŸ§¼ Now You Have:

| Feature                    | Benefit                            |
| -------------------------- | ---------------------------------- |
| Common retry logic         | Cleaner and DRY                    |
| Logging with retry context | Easier to debug                    |
| Configurable retry count   | Tunable per use case               |
| Fail-safe fallback         | Returns empty DataFrame on failure |

Would you like me to bundle this into a retryable `fetch_full_data()` version too?
