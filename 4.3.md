Thanks for the clarification! If you're using **`pymysql`**, the structure remains mostly the same — just with the appropriate `pymysql` classes and error handling.

Here’s an updated version of the batch reader with `pymysql` and retry logic:

---

### ✅ **Robust Batch Reader with `pymysql` + Retry**

```python
import pymysql
import time

class MySQLBatchReader:
    def __init__(self, config, batch_size=25000, max_retries=3, retry_wait=5):
        self.config = config
        self.batch_size = batch_size
        self.max_retries = max_retries
        self.retry_wait = retry_wait
        self.connection = None
        self.cursor = None

    def connect(self):
        retries = 0
        while retries < self.max_retries:
            try:
                self.connection = pymysql.connect(**self.config)
                self.cursor = self.connection.cursor()
                print("Connected to MySQL")
                return
            except pymysql.MySQLError as e:
                print(f"Connection failed: {e}. Retrying in {self.retry_wait} seconds...")
                retries += 1
                time.sleep(self.retry_wait)
        raise Exception("Failed to connect to database after retries")

    def disconnect(self):
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        print("Disconnected from MySQL")

    def read_batches(self, base_query):
        self.connect()
        offset = 0

        while True:
            batch_query = f"{base_query} LIMIT {self.batch_size} OFFSET {offset}"
            retries = 0
            while retries < self.max_retries:
                try:
                    self.cursor.execute(batch_query)
                    rows = self.cursor.fetchall()
                    if not rows:
                        self.disconnect()
                        return
                    yield rows
                    offset += self.batch_size
                    break  # Break retry loop
                except pymysql.MySQLError as e:
                    print(f"Query failed: {e}. Retrying in {self.retry_wait} seconds...")
                    retries += 1
                    time.sleep(self.retry_wait)
                    self.connect()  # Reconnect if needed
```

---

### 🔧 Usage

```python
config = {
    'host': 'localhost',
    'user': 'youruser',
    'password': 'yourpass',
    'database': 'yourdb',
    'cursorclass': pymysql.cursors.DictCursor  # Optional: get results as dicts
}

reader = MySQLBatchReader(config)
query = "SELECT * FROM your_table ORDER BY id"

for batch in reader.read_batches(query):
    process(batch)
```

---

### ⚠️ Notes

* Make sure your server's `wait_timeout` and `interactive_timeout` values are high enough for long jobs, or reconnects may happen more often than you'd like.
* You can use `DictCursor` for easier row access by column names (`row['col_name']`).
* Add logging or file-based checkpoints if you want resume capability in case of a crash.

Would you like to add **file-based resume** (e.g. saving the last offset to a file)?
