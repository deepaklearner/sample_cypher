import pymysql
import logging
import yaml
import pandas as pd
import warnings
from datetime import datetime, timedelta

class IAMDataExport:
    """This class contains all data export scenarios to the Glide database."""

    def __init__(self, database_configs):
        """Get the credentials from the YAML file."""
        self.database_configs = database_configs
        try:
            ssl_options = {'ssl': {'ssl_version': self.database_configs['GLIDE']['TLSVersions']}}
            self.glide_connection = pymysql.connect(
                user=self.database_configs['GLIDE']['Username'],
                password=self.database_configs['GLIDE']['Password'],
                host=self.database_configs['GLIDE']['Hostname'],
                database=self.database_configs['GLIDE']['Database'],
                **ssl_options
            )
            logging.info("GLIDE connection opened successfully !!")
            warnings.filterwarnings('ignore')
        except Exception as e:
            logging.error(f"Exception occurred at get source database connection: {str(e)}")

    def close_connections(self):
        """Close the database connection."""
        try:
            self.glide_connection.close()
            logging.info("GLIDE connection closed successfully !!")
        except Exception:
            logging.error("There is an issue in closing the database connection")

    def backup_table_data(self, table_name, backup_table_name, chunk_size=10000):
        """Backup data from the table."""
        if not self.glide_connection:
            logging.error("No Database connection available")
            return False

        try:
            cursor = self.glide_connection.cursor()
            cursor.execute(f"DESCRIBE {table_name};")
            table_columns = [column[0] for column in cursor.fetchall()]
            column_str = ', '.join(table_columns)
            backup_table_data_status = True
            offset = 0  # start with no rows skipped
            backup_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            while True:
                # Backup a chunk of data
                select_query = f"SELECT {', '.join(table_columns)} FROM {table_name} LIMIT {chunk_size} OFFSET {offset};"
                cursor.execute(select_query)
                rows = cursor.fetchall()

                if not rows:
                    break

                try:
                    # Insert the rows
                    placeholders = ', '.join(['%s'] * (len(table_columns) + 1))
                    backup_query = f"""
                        INSERT INTO {backup_table_name} ({column_str}, BackupTimestamp)
                        VALUES ({placeholders})
                    """
                    data_to_insert = [row + (backup_timestamp,) for row in rows]
                    cursor.executemany(backup_query, data_to_insert)
                    self.glide_connection.commit()
                    logging.info(f"Backed up {len(rows)} rows with offset {offset} to {backup_table_name}, BackupTimestamp: {backup_timestamp}.")
                except Exception as e:
                    logging.error(f"Error during backup: {str(e)}")
                    backup_table_data_status = False
                    break

                offset += chunk_size

        except Exception as e:
            logging.error(f"Error while taking backup of data: {str(e)} - Debug <Class: IAMDataExport | Method: backup_table_data()>")
            backup_table_data_status = False

        return backup_table_data_status

    def del_data_from_table(self, table_name):
        """Delete all data from a table."""
        if not self.glide_connection:
            logging.error("No Database connection available")
            return

        try:
            cursor = self.glide_connection.cursor()
            delete_query = f"DELETE FROM {table_name};"
            cursor.execute(delete_query)
            self.glide_connection.commit()
            logging.info(f"Deleted all data in table {table_name}.")
        except Exception as e:
            logging.error(f"Error deleting data: {str(e)} - Debug <Class: IAMDataExport | Method: del_data_from_table()>")

    def del_7days_old_data(self, backup_table_name):
        """Delete backup data older than 7 days."""
        if not self.glide_connection:
            logging.error("No Database connection available")
            return

        try:
            cursor = self.glide_connection.cursor()
            seven_days_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d %H:%M:%S')
            delete_query = f"DELETE FROM {backup_table_name} WHERE BackupTimestamp < '{seven_days_ago}';"
            cursor.execute(delete_query)
            self.glide_connection.commit()
            logging.info(f"Deleted backup data older than 7 days from {backup_table_name}.")
        except Exception as e:
            logging.error(f"Error fetching data: {str(e)} - Debug <Class: IAMDataExport | Method: del_7days_old_data()>")

    def write_data_to_supervisor_hierarchy(self, df, chunk_size=10000):
        """Write data to the supervisor hierarchy table."""
        if not self.glide_connection:
            logging.error("No Database connection available")
            return

        try:
            df_new = df.copy()
            cursor = self.glide_connection.cursor()
            cursor.execute("DESCRIBE glide.glidesupervisorhierarchy;")
            table_columns = [column[0] for column in cursor.fetchall()]
            table_columns = [col for col in table_columns if col not in ("CreateTimestamp", "ModifyTimestamp")]

            column_mapping = {'EmployeeID': 'employeeid'}
            df_new.rename(columns=column_mapping, inplace=True)
            df_new = df_new[table_columns]

            placeholders = ', '.join(['%s'] * len(table_columns))
            insert_query = f"INSERT INTO glide.glidesupervisorhierarchy ({', '.join(table_columns)}) VALUES ({placeholders})"

            data_to_insert = [tuple(row) for row in df_new.values]
            for start in range(0, len(df_new), chunk_size):
                end = start + chunk_size
                batch = data_to_insert[start:end]
                cursor.executemany(insert_query, batch)
                self.glide_connection.commit()

            cursor.close()
            logging.info("Data written to Glide table supervisor hierarchy successfully.")
        except Exception as e:
            logging.error(f"Error writing data: {str(e)} - Debug <Class: IAMDataExport | Method: write_data_to_supervisor_hierarchy()>")

    def update_data_to_identities(self, df, chunk_size=10000):
        """Update data in the Glide identities table."""
        if not self.glide_connection:
            logging.error("No Database connection available")
            return

        try:
            df_new = df.copy()
            cursor = self.glide_connection.cursor()
            cursor.execute("DESCRIBE glide.glideidentities;")
            table_columns = [column[0] for column in cursor.fetchall()]

            column_mapping = {'EmployeeID': 'resourceid'}
            df_new.rename(columns=column_mapping, inplace=True)

            df_columns = df_new.columns.tolist()
            req_columns = [col for col in df_columns if col in table_columns]

            set_clause = ', '.join([f"{col} = %s" for col in req_columns])
            update_query_template = f"UPDATE glide.glideidentities SET {set_clause} WHERE resourceid = %s"

            req_columns_idx = [df_new.columns.get_loc(col) for col in req_columns]
            resourceid_idx = df_new.columns.get_loc('resourceid')

            for start in range(0, len(df_new), chunk_size):
                end = start + chunk_size
                batch = df_new.iloc[start:end]

                resourceid_ids_in_batch = batch['resourceid'].tolist()
                format_strings = ', '.join(['%s'] * len(resourceid_ids_in_batch))
                query = f"SELECT resourceid FROM glide.glideidentities WHERE resourceid IN ({format_strings})"
                cursor.execute(query, tuple(resourceid_ids_in_batch))
                existing_resource_ids = set(row[0] for row in cursor.fetchall())

                missing_resource_ids = [rid for rid in resourceid_ids_in_batch if rid not in existing_resource_ids]
                if missing_resource_ids:
                    logging.info(f"Missing resourceid values from glide.glideidentities: {missing_resource_ids}")

                data_to_update = [(tuple([row[idx] for idx in req_columns_idx] + [row[resourceid_idx]])) for row in batch.values]

                for data in data_to_update:
                    cursor.execute(update_query_template, data)
                self.glide_connection.commit()

            cursor.close()
            logging.info(f"Data updated in Glide identities table successfully for {len(df_new)} records.")
        except Exception as e:
            logging.error(f"Error updating data: {str(e)} - Debug <Class: IAMDataExport | Method: update_data_to_identities()>")
