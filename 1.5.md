Perfect ‚Äî switching to `UNWIND` with a DataFrame is a **much more scalable and efficient** approach. Below, I‚Äôll show you how to:

1. **Prepare a list of records (dicts)** from your valid DataFrame.
2. **Pass the list to Neo4j in a single Cypher query** using `UNWIND`.
3. **Create Entitlement nodes and `HAS_OWNER` relationships** only for valid owners per row.

---

## ‚úÖ Step-by-step Implementation (Using `UNWIND`)

### üîß 1. Update `process_batch(df)` to pass all valid records at once

```python
def process_batch(df):
    owner_columns = ['owner1', 'owner2', 'owner3']
    all_owner_ids = pd.unique(df[owner_columns].values.ravel())
    all_owner_ids = set(filter(None, all_owner_ids))

    valid_owners = get_valid_owners(all_owner_ids)

    error_rows = []

    # Step: Create list of records to send to Neo4j
    records = []
    for _, row in df.iterrows():
        owners = [row['owner1'], row['owner2'], row['owner3']]
        valid = [o for o in owners if o and o in valid_owners]
        invalid = [o for o in owners if o and o not in valid_owners]

        if not row['entitlementName'] or not row['targetSystem']:
            continue  # skip incomplete keys

        records.append({
            "entitlementID": f"{row['entitlementName']}|{row['targetSystem']}",
            "entitlementName": row['entitlementName'],
            "description": row['description'],
            "riskLevel": row['riskLevel'],
            "priviledgedAccess": row['priviledgedAccess'],
            "entitlementType": row['entitlementType'],
            "targetSystem": row['targetSystem'],
            "validOwners": valid
        })

        if invalid:
            error_rows.append({**row, "invalid_owners": invalid})

    if records:
        with neo4j_driver.session() as session:
            session.write_transaction(create_entitlements_bulk, records)

    return pd.DataFrame(error_rows) if error_rows else pd.DataFrame()
```

---

### üîÅ 2. Define `create_entitlements_bulk()` using `UNWIND`

```python
def create_entitlements_bulk(tx, records):
    query = """
    UNWIND $records AS record
    MERGE (e:Entitlement {entitlementName: record.entitlementName, targetSystem: record.targetSystem})
    SET e.entitlementID = record.entitlementID,
        e.description = record.description,
        e.riskLevel = record.riskLevel,
        e.priviledgedAccess = record.priviledgedAccess,
        e.entitlementType = record.entitlementType

    WITH e, record.validOwners AS owners
    UNWIND owners AS ownerId
    MATCH (u:User {employeeNumber: ownerId})
    MERGE (e)-[:HAS_OWNER]->(u)
    """
    tx.run(query, records=records)
```

---

### ‚öôÔ∏è Notes:
- This pushes all valid entitlements in a **single Cypher transaction**, significantly reducing overhead.
- `record.validOwners` is a list of valid `employeeNumber`s to `MATCH` against `User` nodes.
- Invalid owners are still captured for logging.
- You can scale this easily to **millions of rows**, batch-by-batch.

---

Would you like an optional fallback to write the errors to a CSV or send them to a log?